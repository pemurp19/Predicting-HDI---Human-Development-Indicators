{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb80e43-3f19-41be-893d-b2228810ed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GRU\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Set random seed.\n",
    "np.random.seed(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84843bfb-4d3d-48e1-9910-6c802aa20af4",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d64154f-f60e-4744-8280-eb95e4ffbb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/cleaned_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510a76b2-d34f-447c-9826-da85e60f77b6",
   "metadata": {},
   "source": [
    "-----\n",
    "# Neural Nets Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2889937-6b92-4267-9b27-97df099ad931",
   "metadata": {},
   "source": [
    "### Creating Variables, Train/Test Split & Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697dc74d-0a5c-4a89-8ca8-63bd5fc015a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns= ['HDI', 'Country Name', 'Country Code'])\n",
    "y = df['HDI'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 42)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f1b153-5ec9-4c48-b7b6-60f4bbc27741",
   "metadata": {},
   "source": [
    "### Creating the Initial NN Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cce0cc-ff2e-4be2-88b4-a61ca768cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn_1 = Sequential()\n",
    "\n",
    "model_nn_1.add(Dense(16, activation = 'relu', input_shape = (X.shape[1],)))\n",
    "model_nn_1.add(Dense(32, activation = 'relu'))\n",
    "model_nn_1.add(Dense(1, activation = None))\n",
    "\n",
    "model_nn_1.compile(loss = 'mse',\n",
    "              optimizer = 'adam')\n",
    "\n",
    "history = model_nn_1.fit(X_train_sc, y_train,\n",
    "          epochs = 100,\n",
    "          batch_size = 512,\n",
    "          validation_data = (X_test_sc, y_test),\n",
    "          verbose = 1)\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "epoch_labels = history.epoch\n",
    "\n",
    "plt.figure(figsize=(11, 8))\n",
    "\n",
    "\n",
    "plt.plot(train_loss, label='Training Loss', color='blue')\n",
    "plt.plot(test_loss, label='Testing Loss', color='orange')\n",
    "\n",
    "# Set title\n",
    "plt.title('Training and Testing Loss by Epoch', fontsize=25)\n",
    "plt.xlabel('Epoch', fontsize=18)\n",
    "plt.ylabel('MSE', fontsize=18)\n",
    "plt.xticks(epoch_labels, epoch_labels) \n",
    "\n",
    "plt.legend(fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f650985-03ea-40c7-af4f-2ae5deae69ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_nn_1.predict(X_test_sc)\n",
    "\n",
    "print(r2_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d724f36-5d27-4325-9b9e-aa3ae718c813",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "It is clear that we do not have enough data to run an accurate Neural Net Regression Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae91e6c9-a489-425d-9c93-36fa160d5c95",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ddd86a-8aa6-40a9-b42c-c214692926c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Country Name', 'Country Code', 'HDI'])\n",
    "y = df['HDI']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c26352-6169-4ab9-ba55-b46bbb1819fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate RF Regressor\n",
    "rf_reg = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b199fec-3b3a-42af-b978-1a48423ace3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg_params = {\n",
    "    'n_estimators': [100,150,200,250],\n",
    "    'max_depth': [None, 1,2,3,4,5,10],\n",
    "    'min_samples_leaf': [2,4,6,8,10]\n",
    "}\n",
    "\n",
    "gs=GridSearchCV(rf_reg,\n",
    "               param_grid = rf_reg_params,\n",
    "               cv=5,\n",
    "               n_jobs = -1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "\n",
    "rf_reg = gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1ec7eb-60a6-40d4-9502-c5c338d48b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training R-Squared: {gs.score(X_train, y_train)}')\n",
    "print(f'Training R-Squared: {gs.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae97215e-1281-4f91-84a2-e229ad10d957",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random Forest is overfit compared to the OLS (with select Lasso features)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi] *",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
